\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\usepackage{epigraph}
\usepackage{algorithm}
\usepackage{algpseudocode}

\title{\textbf{Hopeless}\\
\vspace{0.2cm}\normalsize Relazione del progetto per il corso di Algoritmi\\
\normalsize Università di Bologna}

\author{
  E. Argonni,
  S. Musiani
}

\date{2022 - 2023}

\begin{document}

\maketitle

\vspace{1cm}
\textit{"The important thing isn't can you read music, it's can you hear it.
  Can you here the music?"}

% \newpage
% \tableofcontents
% \newpage
\vfill

\section{Introduzione}

Il progetto consisteva nello sviluppare un programma che sapesse giocare nel 
miglior modo possibile il gioco \emph{Connect X}. Quest'ultimo consiste in una
generalizzazione del classico gioco Forza 4 resa possibile da delle 
configurazioni che si distaccavano dalla classica tabella $6 \times 7$ presente 
nel gioco originale e che venivano fornite dal docente.

\section{Il giocatore Small e Big}

Se si da una veloce occhiata al codice si nota che in realtà il giocatore è 
diviso in due: Small e Big. Questa distinzione apparentemente arbitraria è 
necessaria in quanto, come spiegato più avanti nella sezione \ref{sec_bitboard},
la rappresentazione della tabella di gioco tramite Bitboard è possibile solo 
fino alla configurazione $7 \times 7$. Dove possibile quindi è stata adottata 
questa rappresentazione, mentre dove non lo era è stata mantenuta la classica
CXBoard fornita dal docente. Per questo il nome Small e Big: il gicatore Small 
può giocare solo le configurazioni più piccole della $7 \times 7$ compresa, 
mentre il giocatore Big, nonostante possa giocare tutte le configurazioni, si 
limita a quelle rimanenti.

\section{Caratteristiche generali}

Nonostante la divisione dei due giocatori in Small e Big, molti aspetti 
rimangono gli stessi tra i due. Di seguito sono quindi presentati tutti gli 
aspetti comuni ai due giocatori, lasciando per ultimi gli aspetti in cui 
differiscono.

\subsection{PVS}
Forza 4, e di conseguenza anche Connect X, è un gioco a somma-zero e a
informazione perfetta. Queste due proprietà del gioco permettono di implementare
una ricerca basata su MiniMax. Alla base di un qualsiasi giocatore artificiale
vi è infatti un algoritmo di ricerca che permette di esplorare l'albero di tutte
le mosse possibili e determinare quali sono vincenti e quali sono perdenti. In
particolare MiniMax è alla base della ricerca nei giochi a somma-zero e a
informazione perfetta.

L'algoritmo MiniMax, nonostante sia perfettamente funzionante e ritorni sempre
la mossa migliore, è particolarmente inefficiente in quanto richiede di 
esplorare l'intero albero di gioco. Questo porta a dei costi computazionali 
estremamente elevati. Prendiamo per esempio la classica configurazione di Forza 
4 con 6 righe e 7 colonne. Se volessi calcolare l'intero albero di gioco, e 
quindi tutte le possibili configurazioni che si possono ottenere, dovremmo 
considerare $3^{7 \cdot 6} = 3^{42} \approx 1.09 \cdot 10^{20}$. In realtà 
questo è un limite superiore, in quanto molte di queste configurazioni non 
sarebbero valide. Nonostante ciò le configurazioni restano comunque troppe per
essere esplorate tutte in un tempo accettabile. Sono stati quindi inventati 
degli ulteriori algoritmi, che si basano comunque su MiniMax, ma che sono molto 
più efficienti rispetto a quest'ultimo. Il più famoso è AlphaBeta. Non 
riteniamo necessario spiegare il funzionamento di MiniMax e AlphaBeta, ma bensì 
vogliamo dedicare parte di questa relazione ad illustrare la variate di 
AlphaBeta adottata nel nostro giocatore: PVS, o meglio Principal Variation 
Search.

La PVS si basa sul fatto che se esploriamo per prima la linea di gioco 
principale (la Principal Variation), o meglio quella che entrambi i giocatori 
considerano migliore, allora risulta quasi superfluo esplorare completamente 
tutte le altre possibilità di gioco in quanto dovrebbero essere peggiori a 
quella già vista. Questo però non vuol dire che non le esploriamo, ma bensì che 
la loro esplorazione è fatta in modo approssimativo in quanto non mira a 
ottenere un punteggio preciso della variante come farebbe un classico algoritmo 
AlphaBeta, ma punta a capire soltanto se la variante è migliore di quella 
considerata come principale. Se la variante è peggiore il giocatore non fa nulla 
e continua a valutare le altre varianti secondarie finché non le ha concluse, se 
invece la ricerca veloce su quella variante ha ritornato che in realtà è 
migliore della principale si esegue una ricerca completa su quella variante per 
ritornare il punteggio corretto. È necessario infatti puntualizzare che la 
ricerca veloce non restituisce il punteggio corretto associato a quella 
variante, ma soltanto se è migliore o peggiore di quella considerata come 
principale. È quindi necessario eseguire una ricerca completa per determinare il
punteggio corretto se la variante secondaria risulta essere migliore della 
principale.

Nel caso peggiore, ovvero quello in cui ogni variante secondaria risulta essere
migliore della variante principale considerata in precedenza, l'algoritmo PVS 
risulta essere più lento del classico AlphaBeta. Questo caso pessimo però è 
molto raro, sopratutto se si integra PVS un riordinamento delle mosse in modo
da considerare prima quelle che risulta essere più promettenti.

Di seguito è presentata una versione in pseudo-codice dell'algoritmo PVS:

\begin{algorithm}[H]
  \caption{\textsc{PrincipalVariationSearch}}
  \label{alg_pvs}
  \begin{algorithmic}[0]
    \Function {PVS}{$Board$, $\alpha$, $\beta$, $depth$, $color$}

      \If{$depth = 0$ \textbf{or} $node$ is a leaf}
        \State \Return $color \cdot \Call{Evaluate}{Board}$
      \EndIf
      \\
      \State $bSearchPV \gets true$
      \For{$move$ \textbf{in} \Call{Sorted}{$Board.availableMoves()$}}
        \State $B.makeMove(move)$
        \If{$bSearchPV$}
          \Comment{\`E la \emph{Principal Variation}}
          \State $score \gets -\Call{PVS}{B, -beta, -alpha, depth - 1, \textrm{not } color}$
        \Else
          \Comment{Ricerca veloce sulle varianti secondarie}
          \State $score \gets -\Call{fastSearch}{B, -alpha, depth - 1, \textrm{not } color}$
          \If{$\alpha < score < \beta$}
            \Comment{\`E un nodo interessante}
            \State $score \gets -\Call{PVS}{B, -beta, -alpha, depth - 1, \textrm{not } color}\}$
            \State $\alpha \gets \max\{\alpha, score\}$
          \EndIf
        \EndIf
        \State $B.unamkeMove()$
        \\
        \If{$score \geq \beta$}
        \Comment{Potatura $\alpha$-$\beta$}
        \State \textbf{return} beta;
        \EndIf
        \If{$score > alpha$}
          \State $\alpha \gets score$
        \EndIf
        \State $bSearchPV \gets false$
      \EndFor
      \State \Return $alpha$
    \EndFunction

  \end{algorithmic}
\end{algorithm}

Si noti che utilizzando la proprietà di somma-zero del gioco preso in analisi, 
si può utilizzare la stessa funzione di ricerca sia per il giocatore che 
massimizza sia per il giocatore che minimizza semplicemente negando la chiamata
alla funzione successiva e invertendo $\alpha$ e $\beta$.

La ricerca principale nell'algoritmo PVS è come un normalissimo AlphaBeta se non
si considerano le ricerche veloci. La chiamata iniziale di PVS è infatti con i
parametri $\alpha$ e $\beta$ rispettivamente $-\infty$ e $+\infty$. Quello che 
però appunto distingue PVS è la ricerca veloce.

La fastSearch non è altro che un AlphaBeta modificato in modo che i parametri 
$\alpha$ e $\beta$ riducano la finestra talmente tanto da risultare quasi nulla.
Questo permette di tagliare tantissimi rami e fare in modo che la ricerca sia
effettivamente più veloce.

\begin{algorithm}
  \caption{\textsc{fastSearch}}
  \label{alg_fastSeach}
  \begin{algorithmic}
    \Function {fastSearch}{$Board$, $\beta$, $depth$, $color$}

      \If{$depth = 0$ \textbf{or} $node$ is a leaf}
        \State \Return $color \cdot \Call{Evaluate}{Board}$
      \EndIf
      \\
      \For{$move$ \textbf{in} $Board.availableMoves()$}
        \State $B.makeMove(move)$
        \State $score \gets -\Call{fastSearch}{B, 1 - beta, depth - 1, \textrm{not } color}$
        \State $B.unamkeMove()$
        \\
        \If{$score \geq \beta$}
        \Comment{Potatura $\alpha$-$\beta$}
        \State \textbf{return} beta;
        \EndIf
      \EndFor
      \State \Return $beta - 1$
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\subsection{Iterative deepening}
Il framework Iterative Deepening (ID) è una tecnica di ricerca adottata come 
metodo base per la gestione del tempo nella scelta di una mossa negli algoritmi 
che sfruttano la ricerca in profondità (Depth-First search, DFS) come PVS. 
L'idea alla base di questa strategia è quella di effettuare una serie 
di iterazioni dell'algoritmo di ricerca in profondità, aumentando gradualmente 
la profondità massima dell'albero esplorato. Ad ogni iterazione, l'algoritmo 
effettua una ricerca in profondità limitata (Depth-Limited search, DLS) e, alla
conclusione, memorizza la mossa migliore fino a quel momento trovata. 
Successivamente ricomincia la ricerca con una profondità maggiore. Questo 
procedimento continua fino a che il tempo non scade, momento in cui la mossa 
migliore fino a quel momento viene ritornata.

\begin{algorithm}
  \caption{\textsc{iterativeDeepening}}
  \label{alg_iterativeDeepening}
  \begin{algorithmic}
    \State $previousDepthSearch \gets 2$
    \Comment{Variabili globali}
    \State $currentBestMove \gets 0$
    \\
    \Function {IterativeDeepening}{$Board$}
      \State $depth \gets 2$
      \If{$amIFirst$}
        \Comment{Sono il primo giocatore}
        \State $depth \gets \Call{max}{previousDepthSearch - 2, 2}$
      \Else
        \State $depth \gets \Call{max}{previousDepthSearch - 2, 1}$ 
      \EndIf
      \\
      \State $searchNotFinished \gets true$
      \While{searchNotFinished}
        \Comment{Non ho visitato ancora tutte le foglie} 
        \State $currentBestMove \gets \Call{movePVS}{Board, depth}$
        \If{GameTree is all visited}
          \Comment{Ho visitato tutto l'albero}
          \State $searchNotFinished \gets false$
        \EndIf
        \State $previousDepthSearch \gets depth$
        \State $depth \gets depth + 2$
      \EndWhile
      \State \Return $currentBestMove$
    \EndFunction
  \end{algorithmic}
\end{algorithm}

\textsc{movePvSearch} è una variante di PVS in cui non viene ritornato il 
valore della posizione ma bensì la mossa migliore nella posizione attuale.

Si noti che nell'algoritmo presentato la profondità viene inizializzata in base 
al giocatore che inizia la partita. Inoltre l'aumento ad ogni iterazione della 
profondità non è di 1 ma bensì di 2. È necessario fare entrambe queste 
variazioni all'algoritmo generale descritto sopra per valutare solo le 
profondità in cui entrambi i giocatori hanno lo stesso numero di pedine in 
gioco. Questo è necessario perché se si valutassero profondità finali con un 
numero diverso di pedine per i due giocatori, uno di essi risulterebbe sempre in 
vantaggio. Ovviamente siamo costretti a valutare posizioni intermede in cui il
primo giocatore avrà posizionato una pedina in più rispetto al secondo, ma 
questo non avviene nello stadio finale della ricerca in cui è necessario 
scegliere la mossa migliore.

Se il tempo massimo che il giocatore ha per eseguire una mossa scade durante
la ricerca PVS, viene ritornata immediatamente la mossa migliore che è salvata
nella variabile globale $currentBestMove$.

La variabile $previousDepthSearch$ serve per memorizzare la profondità che il
giocatore ha raggiunto nella precedente chiamata di ID. In questo modo, se nella
precedente chiamata eseguiamo una ricerca a tutte le profondità fino alla numero 
$n$, nella chiamata successiva puntiamo direttamente alla profondità $n - 2$ in 
quanto siamo praticamente certi di poterla raggiungere nel tempo dato.


\subsection{Transposition table}
\label{sec_transpositionTable}
Come funziona
Non è necessaria, ma aiuta ad evitare calcoli.

\subsection{Ordine delle mosse}
Ordinamento centrale
(Test sulla PV?)

\subsection{Euristica}
\subsubsection{Come viene valutata una posizione}
\subsubsection{Euristica incrementale}
\subsubsection{Miglioramenti riscontrati}
\subsubsection{Ammortizzazione e valori quadratici}

\section{Bitboard in Small}
\label{sec_bitboard}
\subsection{Funzionamento}
\subsection{Valutazione di una vittoria}
\subsection{Controllo di una casella specifica}
\subsection{Hash per la Transposition table}
\subsection{Miglioramenti riscontrati}

\section{Zobrist: hash per Big}

\section{Possibili miglioramenti}
\section{Conclusione}

\end{document}

